### KN (YT) ###

Video 1:


Video 2: 


Video 3: 


Video 4: 


Video 5: 


Video 6: 


Video 7: 


Video 8: 


Video 9: 


Video 10: 


Video 11: Seaborn
Univariate analysis (one feature)
Bivariate analysis (two features)
more than 2 features (use seaborn)


Video 12: 


Video 13: 


Video 14: How to become good in exploratory data analysis (EDA)

Video 15: EDA of Titanic dataset
nominal -> not ordered
ordinal -> ordered

Video 16: 


Video 17: 


Video 18: 


Video 19: 


Video 20: 


Video 21: 


Video 22: 


Video 23: 


Video 24: 


Video 25: 


Video 26: 


Video 27: 


Video 28: 


Video 29: Univariate, Bivariate, and Multivariate - Part 1 (EDA)



Video 30: 


Video 31: 


Video 32: 


Video 33: 


Video 34: 


Video 35: 


Video 36: 


Video 37: 


Video 38: 


Video 39: 


Video 40: 


Video 41: 


Video 42: 


Video 43: 


Video 44: 


Video 45: Performance Metrics for "classification problem" in machine learning
2 types of classification problem -> class labels (category A and B) and probabilities
Balanced dataset -> Use Accuracy
Unbalanced dataset -> Use Recall (aka True positive rate and sensitivity), Precision (aka positive prediction value), and F Beta
confusion matrix -> is a 2 by 2 matrix (in case of binary classification problem)
                 ->  [TP                   ,  FP (aka type 1 error)]
                 ->  [FN (aka type 2 error),  TN]
                 -> Top (actual values), Side (predicted values)
                 ->
Type 1 error = FP/(FP+TN)
Type 2 error = FP/(TP+FN)
Accuracy = (TP + TN) / (TP + FP + FN + TN)
Recall = TP/ (TP+FN) # of all positive actual values, how many values did we correctly predict positively
       = use when FN is more important (ie whether stock market is gonna crash or not)
Precision = TP/ (TP + FP) # of all positive predicted values, how many were actually positive
          = use when FP is more important (spam detection)
F Beta = (1+beta**2) * ( (Precision*Recall) / (beta**2)*(Precision+Recall) )
       = use when FP and FN both are very important
       = when beta is 1, we call it F1 score. Select beta = 1 when FN and FP have same importance
       = Reduce beta value when type 1 error is more important than type 2 error
       = Increase beta value (greater than 1) when type 2 error is more important than type 1 error
       = beta values ranges from 2-10 when FN > FP and 0-1 when FP > FN in terms of their importance




Video 46: 


Video 47: 


Video 48: 


Video 49: 


Video 50: 


Video 51: 


Video 52: 


Video 53: 


Video 54: 


Video 55: 


Video 56: 


Video 57: 


Video 58: Performance Metrics for classification problem in ML - Part 2
ROC (receiver operating characteristic curve)
AUC (Area under the ROC curve)
# plot a graph with TPR on y-axis and FPR on x-axis, points are dependent on initial thresholds that we specify
# Draw a line from origin to right-most point
# Choose the most suitable threshold from graph

Video 59: 


Video 60: 


Video 61: 


Video 62: 


Video 63: 


Video 64: 


Video 65: 


Video 66: 


Video 67: 


Video 68: 


Video 69: 


Video 70: 


Video 71: 


Video 72: 


Video 73: 


Video 74: 


Video 75: 


Video 76: 


Video 77: 


Video 78: 


Video 79: 


Video 80: 


Video 81: 


Video 82: 


Video 83: 


Video 84: 


Video 85: 


Video 86: 


Video 87: 


Video 88: 


Video 89: 


Video 90: 


Video 91: 


Video 92: 


Video 93: 


Video 94: 


Video 95: 


Video 96: 


Video 97: 


Video 98: 


Video 99: 


Video 100: 


